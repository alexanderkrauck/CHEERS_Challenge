{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "considerable-collectible",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "import os\n",
    "from ast import literal_eval\n",
    "import itertools\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "significant-china",
   "metadata": {},
   "source": [
    "# 1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "mounted-saturn",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = \"data_round_1\"\n",
    "\n",
    "l_train_documents = pd.read_csv(os.path.join(data_location,\"documents_en_train.csv\"))\n",
    "l_validation_documents = pd.read_csv(os.path.join(data_location,\"documents_en_val.csv\"))\n",
    "l_test_documents = pd.read_csv(os.path.join(data_location,\"documents_en_test.csv\"))\n",
    "        \n",
    "l_train_sentences = pd.read_csv(os.path.join(data_location,\"sentences_en_train.csv\"), converters={'sector_ids': literal_eval})\n",
    "l_validation_sentences = pd.read_csv(os.path.join(data_location,\"sentences_en_val.csv\"), converters={'sector_ids': literal_eval})\n",
    "l_test_sentences = pd.read_csv(os.path.join(data_location,\"sentences_en_test.csv\"), converters={'sector_ids': literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "relevant-point",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_name</th>\n",
       "      <th>country_code</th>\n",
       "      <th>lang_code</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>doc_text</th>\n",
       "      <th>doc_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMMAP/DFS Syria</td>\n",
       "      <td>SYR</td>\n",
       "      <td>en</td>\n",
       "      <td>48582</td>\n",
       "      <td>This website uses cookies to improve your experience. We'll assume you're ok with this, but you can opt-out if you wish.Accept</td>\n",
       "      <td>https://www.syriahr.com/en/203844/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMMAP/DFS Syria</td>\n",
       "      <td>SYR</td>\n",
       "      <td>en</td>\n",
       "      <td>41032</td>\n",
       "      <td>Please enable Cookies and reload the page.\\n\\nThis process is automatic. Your browser will redirect to your requested content shortly.\\n\\nPlease allow up to 5 secondsâ€¦</td>\n",
       "      <td>https://www.syriahr.com/en/187230/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence_text</th>\n",
       "      <th>is_relevant</th>\n",
       "      <th>sector_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51657</td>\n",
       "      <td>0</td>\n",
       "      <td>New Salesian youth center in La Cecilia district serves more than 100 youth (MissionNewswire) Salesian missionaries have opened a youth center in the La Cecilia district of Armenia, Colombia.</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51657</td>\n",
       "      <td>1</td>\n",
       "      <td>Armenia is at the center of the Colombian coffee growing axis.</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(l_train_documents.head(2).to_html()))\n",
    "display(HTML(l_train_sentences.head(2).to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "general-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_documents = l_train_documents.copy().set_index(\"doc_id\")\n",
    "validation_documents = l_validation_documents.copy().set_index(\"doc_id\")\n",
    "test_documents = l_test_documents.copy().set_index(\"doc_id\")\n",
    "\n",
    "#Adding one feature here already because its easier on this data-format\n",
    "l_train_sentences[\"sentence_position\"] = l_train_sentences[\"sentence_id\"].apply(lambda x: np.log(x+1))\n",
    "l_validation_sentences[\"sentence_position\"] = l_validation_sentences[\"sentence_id\"].apply(lambda x: np.log(x+1))\n",
    "l_test_sentences[\"sentence_position\"] = l_test_sentences[\"sentence_id\"].apply(lambda x: np.log(x+1))\n",
    "\n",
    "train_sentences = l_train_sentences.copy().set_index([\"doc_id\",\"sentence_id\"])\n",
    "validation_sentences = l_validation_sentences.copy().set_index([\"doc_id\",\"sentence_id\"])\n",
    "test_sentences = l_test_sentences.copy().set_index([\"doc_id\",\"sentence_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-relative",
   "metadata": {},
   "source": [
    "# 2 Change nominal features to Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "therapeutic-theology",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_documents[\"doc_url\"].fillna(\"\",inplace=True)\n",
    "validation_documents[\"doc_url\"].fillna(\"\",inplace=True)\n",
    "test_documents[\"doc_url\"].fillna(\"\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "requested-consortium",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name_mapping = dict((o,idx) for idx, o in enumerate(set(train_documents[\"project_name\"])))\n",
    "country_code_mapping = dict((o,idx) for idx, o in enumerate(set(train_documents[\"country_code\"])))\n",
    "url_set = set(train_documents[\"doc_url\"].apply(lambda x: urlparse(x).netloc))\n",
    "document_url_mapping = dict((o,idx) for idx, o in enumerate(url_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "instrumental-tsunami",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_documents.replace(project_name_mapping, inplace=True)\n",
    "validation_documents.replace(project_name_mapping, inplace=True)\n",
    "test_documents.replace(project_name_mapping, inplace=True)\n",
    "\n",
    "train_documents.replace(country_code_mapping, inplace=True)\n",
    "validation_documents.replace(country_code_mapping, inplace=True)\n",
    "test_documents.replace(country_code_mapping, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "known-chain",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_documents[\"url\"] = train_documents[\"doc_url\"].apply(lambda x: urlparse(x).netloc).replace(document_url_mapping)\n",
    "validation_documents[\"url\"] = validation_documents[\"doc_url\"].apply(lambda x: urlparse(x).netloc).replace(document_url_mapping)\n",
    "test_documents[\"url\"] = test_documents[\"doc_url\"].apply(lambda x: urlparse(x).netloc).replace(document_url_mapping)\n",
    "#Make unknown (from train set) urls a seperate index\n",
    "for item in validation_documents.iterrows():\n",
    "    if urlparse(item[1][\"doc_url\"]).netloc not in url_set:\n",
    "        validation_documents.loc[item[0], \"url\"] = len(url_set)\n",
    "        \n",
    "for item in test_documents.iterrows():\n",
    "    if urlparse(item[1][\"doc_url\"]).netloc not in url_set:\n",
    "        test_documents.loc[item[0], \"url\"] = len(url_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-atlas",
   "metadata": {},
   "source": [
    "# 3 Extract some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "christian-highway",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract document length\n",
    "train_documents[\"text_length\"] = train_documents[\"doc_text\"].apply(len).apply(np.log) #the idea behind log is that the net can use it better (but maybe it is wrong?)\n",
    "validation_documents[\"text_length\"] = validation_documents[\"doc_text\"].apply(len).apply(np.log)\n",
    "test_documents[\"text_length\"] = test_documents[\"doc_text\"].apply(len).apply(np.log)\n",
    "\n",
    "#Extract sentence count in document\n",
    "train_documents[\"sentence_count\"] = train_sentences.groupby(level=\"doc_id\").size().apply(np.log)\n",
    "validation_documents[\"sentence_count\"] = validation_sentences.groupby(level=\"doc_id\").size().apply(np.log)\n",
    "test_documents[\"sentence_count\"] = test_sentences.groupby(level=\"doc_id\").size().apply(np.log)\n",
    "\n",
    "#Extract Sentence Length\n",
    "train_sentences[\"sentence_length\"] = train_sentences[\"sentence_text\"].apply(len).apply(np.log)\n",
    "validation_sentences[\"sentence_length\"] = validation_sentences[\"sentence_text\"].apply(len).apply(np.log)\n",
    "test_sentences[\"sentence_length\"] = test_sentences[\"sentence_text\"].apply(len).apply(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "transsexual-connection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_name</th>\n",
       "      <th>country_code</th>\n",
       "      <th>lang_code</th>\n",
       "      <th>doc_text</th>\n",
       "      <th>doc_url</th>\n",
       "      <th>url</th>\n",
       "      <th>text_length</th>\n",
       "      <th>sentence_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40328</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>en</td>\n",
       "      <td>Coxâ€™s Bazar â€“ The International Organization f...</td>\n",
       "      <td>https://reliefweb.int/report/bangladesh/iom-am...</td>\n",
       "      <td>86</td>\n",
       "      <td>7.983099</td>\n",
       "      <td>2.772589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39775</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>Introduction The continuation of conflict in N...</td>\n",
       "      <td>https://reliefweb.int/sites/reliefweb.int/file...</td>\n",
       "      <td>86</td>\n",
       "      <td>9.124456</td>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47025</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>en</td>\n",
       "      <td>Damascus, SANA- Al Mujtahed Â Damascus Hospital...</td>\n",
       "      <td>http://sana.sy/en/?p=216501</td>\n",
       "      <td>66</td>\n",
       "      <td>7.271704</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44256</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>Kongoussi, Burkina Faso â€”Editor's note: In a M...</td>\n",
       "      <td>https://allafrica.com/stories/202010130090.html</td>\n",
       "      <td>61</td>\n",
       "      <td>9.229456</td>\n",
       "      <td>4.110874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35135</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>en</td>\n",
       "      <td>Pandemic Also Opportunity for Business Elite t...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>8.122074</td>\n",
       "      <td>2.944439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44892</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>en</td>\n",
       "      <td>CCCM and Shelter/NFI Clustersâ€™ Fire Prevention...</td>\n",
       "      <td>https://reliefweb.int/sites/reliefweb.int/file...</td>\n",
       "      <td>86</td>\n",
       "      <td>9.627009</td>\n",
       "      <td>4.624973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51667</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>en</td>\n",
       "      <td>Bangladeshâ€™s daily infection rate fell slightl...</td>\n",
       "      <td>https://unb.com.bd/category/Bangladesh/covid-1...</td>\n",
       "      <td>73</td>\n",
       "      <td>8.129470</td>\n",
       "      <td>3.367296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40325</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>en</td>\n",
       "      <td>Bangladesh is hosting more than one million Ro...</td>\n",
       "      <td>https://reliefweb.int/report/bangladesh/bangla...</td>\n",
       "      <td>86</td>\n",
       "      <td>7.973500</td>\n",
       "      <td>2.995732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34596</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>en</td>\n",
       "      <td>July 2020 | Round 2 How COVID-19 compounds alr...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>10.176982</td>\n",
       "      <td>4.934474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51682</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>en</td>\n",
       "      <td>File photo of In a densely populated city like...</td>\n",
       "      <td>https://www.dhakatribune.com/health/coronaviru...</td>\n",
       "      <td>131</td>\n",
       "      <td>7.952615</td>\n",
       "      <td>3.135494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>343 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        project_name  country_code lang_code  \\\n",
       "doc_id                                         \n",
       "40328              3             4        en   \n",
       "39775              5             1        en   \n",
       "47025              0             2        en   \n",
       "44256              1             0        en   \n",
       "35135              0             2        en   \n",
       "...              ...           ...       ...   \n",
       "44892              0             2        en   \n",
       "51667              3             4        en   \n",
       "40325              3             4        en   \n",
       "34596              0             2        en   \n",
       "51682              3             4        en   \n",
       "\n",
       "                                                 doc_text  \\\n",
       "doc_id                                                      \n",
       "40328   Coxâ€™s Bazar â€“ The International Organization f...   \n",
       "39775   Introduction The continuation of conflict in N...   \n",
       "47025   Damascus, SANA- Al Mujtahed Â Damascus Hospital...   \n",
       "44256   Kongoussi, Burkina Faso â€”Editor's note: In a M...   \n",
       "35135   Pandemic Also Opportunity for Business Elite t...   \n",
       "...                                                   ...   \n",
       "44892   CCCM and Shelter/NFI Clustersâ€™ Fire Prevention...   \n",
       "51667   Bangladeshâ€™s daily infection rate fell slightl...   \n",
       "40325   Bangladesh is hosting more than one million Ro...   \n",
       "34596   July 2020 | Round 2 How COVID-19 compounds alr...   \n",
       "51682   File photo of In a densely populated city like...   \n",
       "\n",
       "                                                  doc_url  url  text_length  \\\n",
       "doc_id                                                                        \n",
       "40328   https://reliefweb.int/report/bangladesh/iom-am...   86     7.983099   \n",
       "39775   https://reliefweb.int/sites/reliefweb.int/file...   86     9.124456   \n",
       "47025                         http://sana.sy/en/?p=216501   66     7.271704   \n",
       "44256     https://allafrica.com/stories/202010130090.html   61     9.229456   \n",
       "35135                                                        0     8.122074   \n",
       "...                                                   ...  ...          ...   \n",
       "44892   https://reliefweb.int/sites/reliefweb.int/file...   86     9.627009   \n",
       "51667   https://unb.com.bd/category/Bangladesh/covid-1...   73     8.129470   \n",
       "40325   https://reliefweb.int/report/bangladesh/bangla...   86     7.973500   \n",
       "34596                                                        0    10.176982   \n",
       "51682   https://www.dhakatribune.com/health/coronaviru...  131     7.952615   \n",
       "\n",
       "        sentence_count  \n",
       "doc_id                  \n",
       "40328         2.772589  \n",
       "39775         3.496508  \n",
       "47025         1.609438  \n",
       "44256         4.110874  \n",
       "35135         2.944439  \n",
       "...                ...  \n",
       "44892         4.624973  \n",
       "51667         3.367296  \n",
       "40325         2.995732  \n",
       "34596         4.934474  \n",
       "51682         3.135494  \n",
       "\n",
       "[343 rows x 8 columns]"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biblical-object",
   "metadata": {},
   "source": [
    "- Maybe add target encoding (but I am not sure if it is so powerful since we do not have so many nominal classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-gibson",
   "metadata": {},
   "source": [
    "# 4 Tokenize sentences (first 512 tokens) & remove sentence feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "unsigned-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences[\"tokenized_sentence\"] = train_sentences[\"sentence_text\"].apply(lambda x: tokenizer(x, max_length=512, truncation=\"longest_first\")[\"input_ids\"])\n",
    "validation_sentences[\"tokenized_sentence\"] = validation_sentences[\"sentence_text\"].apply(lambda x: tokenizer(x, max_length=512, truncation=\"longest_first\")[\"input_ids\"])\n",
    "test_sentences[\"tokenized_sentence\"] = test_sentences[\"sentence_text\"].apply(lambda x: tokenizer(x, max_length=512, truncation=\"longest_first\")[\"input_ids\"])\n",
    "\n",
    "train_sentences.drop(\"sentence_text\", axis=\"columns\", inplace= True)\n",
    "validation_sentences.drop(\"sentence_text\", axis=\"columns\", inplace= True)\n",
    "test_sentences.drop(\"sentence_text\", axis=\"columns\", inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-madrid",
   "metadata": {},
   "source": [
    "# 5 Remove unnecessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "welcome-understanding",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_documents.drop(\"lang_code\",axis=\"columns\", inplace = True)\n",
    "validation_documents.drop(\"lang_code\",axis=\"columns\", inplace = True)\n",
    "test_documents.drop(\"lang_code\",axis=\"columns\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "portuguese-friendship",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_documents.drop(\"doc_text\",axis=\"columns\", inplace = True)\n",
    "validation_documents.drop(\"doc_text\",axis=\"columns\", inplace = True)\n",
    "test_documents.drop(\"doc_text\",axis=\"columns\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "danish-karma",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_documents.drop(\"doc_url\",axis=\"columns\", inplace = True)\n",
    "validation_documents.drop(\"doc_url\",axis=\"columns\", inplace = True)\n",
    "test_documents.drop(\"doc_url\",axis=\"columns\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "becoming-running",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_name</th>\n",
       "      <th>country_code</th>\n",
       "      <th>url</th>\n",
       "      <th>text_length</th>\n",
       "      <th>sentence_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48582</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4.836282</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41032</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5.093750</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>is_relevant</th>\n",
       "      <th>sector_ids</th>\n",
       "      <th>sentence_position</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>tokenized_sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">51657</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.252273</td>\n",
       "      <td>[101, 1203, 15689, 1811, 3298, 2057, 1107, 2001, 20391, 1629, 3411, 1167, 1190, 1620, 3298, 113, 5852, 2249, 17540, 24952, 114, 15689, 1811, 12799, 1138, 1533, 170, 3298, 2057, 1107, 1103, 2001, 20391, 1629, 1104, 9917, 117, 6855, 119, 102]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>4.127134</td>\n",
       "      <td>[101, 9917, 1110, 1120, 1103, 2057, 1104, 1103, 13977, 3538, 2898, 9840, 119, 102]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(train_documents.head(2).to_html()))\n",
    "display(HTML(train_sentences.head(2).to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-banana",
   "metadata": {},
   "source": [
    "# 6 Join together and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "million-phrase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>is_relevant</th>\n",
       "      <th>sector_ids</th>\n",
       "      <th>sentence_position</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>tokenized_sentence</th>\n",
       "      <th>project_name</th>\n",
       "      <th>country_code</th>\n",
       "      <th>url</th>\n",
       "      <th>text_length</th>\n",
       "      <th>sentence_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">51657</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.252273</td>\n",
       "      <td>[101, 1203, 15689, 1811, 3298, 2057, 1107, 200...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "      <td>7.699389</td>\n",
       "      <td>2.944439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>4.127134</td>\n",
       "      <td>[101, 9917, 1110, 1120, 1103, 2057, 1104, 1103...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "      <td>7.699389</td>\n",
       "      <td>2.944439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>4.682131</td>\n",
       "      <td>[101, 1109, 1207, 3298, 2057, 1144, 1462, 1167...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "      <td>7.699389</td>\n",
       "      <td>2.944439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>4.875197</td>\n",
       "      <td>[101, 1109, 15689, 1811, 3298, 2057, 1108, 187...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "      <td>7.699389</td>\n",
       "      <td>2.944439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>4.204693</td>\n",
       "      <td>[101, 2408, 1104, 1292, 3298, 1435, 1121, 2869...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "      <td>7.699389</td>\n",
       "      <td>2.944439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">34512</th>\n",
       "      <th>121</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>4.804021</td>\n",
       "      <td>4.234107</td>\n",
       "      <td>[101, 1438, 117, 13879, 22346, 1116, 1132, 113...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10.068493</td>\n",
       "      <td>4.836282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>4.812184</td>\n",
       "      <td>5.017280</td>\n",
       "      <td>[101, 1130, 5008, 117, 1175, 1132, 3756, 1104,...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10.068493</td>\n",
       "      <td>4.836282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>4.820282</td>\n",
       "      <td>4.234107</td>\n",
       "      <td>[101, 1109, 9690, 12240, 1708, 1264, 1209, 171...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10.068493</td>\n",
       "      <td>4.836282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>4.828314</td>\n",
       "      <td>4.174387</td>\n",
       "      <td>[101, 1192, 1169, 1525, 1126, 24431, 1104, 115...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10.068493</td>\n",
       "      <td>4.836282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>4.836282</td>\n",
       "      <td>5.420535</td>\n",
       "      <td>[101, 1429, 9690, 12240, 1708, 145, 25810, 149...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10.068493</td>\n",
       "      <td>4.836282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261981 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    is_relevant sector_ids  sentence_position  \\\n",
       "doc_id sentence_id                                              \n",
       "51657  0                      0         []           0.000000   \n",
       "       1                      0         []           0.693147   \n",
       "       2                      0         []           1.098612   \n",
       "       3                      0         []           1.386294   \n",
       "       4                      0         []           1.609438   \n",
       "...                         ...        ...                ...   \n",
       "34512  121                    0         []           4.804021   \n",
       "       122                    0         []           4.812184   \n",
       "       123                    0         []           4.820282   \n",
       "       124                    0         []           4.828314   \n",
       "       125                    0         []           4.836282   \n",
       "\n",
       "                    sentence_length  \\\n",
       "doc_id sentence_id                    \n",
       "51657  0                   5.252273   \n",
       "       1                   4.127134   \n",
       "       2                   4.682131   \n",
       "       3                   4.875197   \n",
       "       4                   4.204693   \n",
       "...                             ...   \n",
       "34512  121                 4.234107   \n",
       "       122                 5.017280   \n",
       "       123                 4.234107   \n",
       "       124                 4.174387   \n",
       "       125                 5.420535   \n",
       "\n",
       "                                                   tokenized_sentence  \\\n",
       "doc_id sentence_id                                                      \n",
       "51657  0            [101, 1203, 15689, 1811, 3298, 2057, 1107, 200...   \n",
       "       1            [101, 9917, 1110, 1120, 1103, 2057, 1104, 1103...   \n",
       "       2            [101, 1109, 1207, 3298, 2057, 1144, 1462, 1167...   \n",
       "       3            [101, 1109, 15689, 1811, 3298, 2057, 1108, 187...   \n",
       "       4            [101, 2408, 1104, 1292, 3298, 1435, 1121, 2869...   \n",
       "...                                                               ...   \n",
       "34512  121          [101, 1438, 117, 13879, 22346, 1116, 1132, 113...   \n",
       "       122          [101, 1130, 5008, 117, 1175, 1132, 3756, 1104,...   \n",
       "       123          [101, 1109, 9690, 12240, 1708, 1264, 1209, 171...   \n",
       "       124          [101, 1192, 1169, 1525, 1126, 24431, 1104, 115...   \n",
       "       125          [101, 1429, 9690, 12240, 1708, 145, 25810, 149...   \n",
       "\n",
       "                    project_name  country_code  url  text_length  \\\n",
       "doc_id sentence_id                                                 \n",
       "51657  0                       2             3   65     7.699389   \n",
       "       1                       2             3   65     7.699389   \n",
       "       2                       2             3   65     7.699389   \n",
       "       3                       2             3   65     7.699389   \n",
       "       4                       2             3   65     7.699389   \n",
       "...                          ...           ...  ...          ...   \n",
       "34512  121                     0             2    0    10.068493   \n",
       "       122                     0             2    0    10.068493   \n",
       "       123                     0             2    0    10.068493   \n",
       "       124                     0             2    0    10.068493   \n",
       "       125                     0             2    0    10.068493   \n",
       "\n",
       "                    sentence_count  \n",
       "doc_id sentence_id                  \n",
       "51657  0                  2.944439  \n",
       "       1                  2.944439  \n",
       "       2                  2.944439  \n",
       "       3                  2.944439  \n",
       "       4                  2.944439  \n",
       "...                            ...  \n",
       "34512  121                4.836282  \n",
       "       122                4.836282  \n",
       "       123                4.836282  \n",
       "       124                4.836282  \n",
       "       125                4.836282  \n",
       "\n",
       "[261981 rows x 10 columns]"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_joint = train_sentences.join(train_documents, on=\"doc_id\")\n",
    "validation_joint = validation_sentences.join(validation_documents, on=\"doc_id\")\n",
    "test_joint = test_sentences.join(test_documents, on=\"doc_id\")\n",
    "train_joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "abandoned-toronto",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexa\\.conda\\envs\\main\\lib\\site-packages\\pandas\\core\\generic.py:2606: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['sector_ids', 'tokenized_sentence'], dtype='object')]\n",
      "\n",
      "  pytables.to_hdf(\n",
      "C:\\Users\\alexa\\.conda\\envs\\main\\lib\\site-packages\\pandas\\core\\generic.py:2606: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed-integer,key->block2_values] [items->Index(['sector_ids', 'tokenized_sentence', 'url'], dtype='object')]\n",
      "\n",
      "  pytables.to_hdf(\n",
      "C:\\Users\\alexa\\.conda\\envs\\main\\lib\\site-packages\\pandas\\core\\generic.py:2606: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed-integer,key->block2_values] [items->Index(['tokenized_sentence', 'url'], dtype='object')]\n",
      "\n",
      "  pytables.to_hdf(\n"
     ]
    }
   ],
   "source": [
    "train_joint.to_hdf(os.path.join(\"preprocessed_data\", \"train_joint.h5\"), key='s')\n",
    "validation_joint.to_hdf(os.path.join(\"preprocessed_data\", \"validation_joint.h5\"), key='s')\n",
    "test_joint.to_hdf(os.path.join(\"preprocessed_data\", \"test_joint.h5\"), key='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "hazardous-metallic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexa\\.conda\\envs\\main\\lib\\site-packages\\pandas\\core\\generic.py:2606: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->Index(['sector_ids', 'tokenized_sentence'], dtype='object')]\n",
      "\n",
      "  pytables.to_hdf(\n",
      "C:\\Users\\alexa\\.conda\\envs\\main\\lib\\site-packages\\pandas\\core\\generic.py:2606: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->Index(['tokenized_sentence'], dtype='object')]\n",
      "\n",
      "  pytables.to_hdf(\n"
     ]
    }
   ],
   "source": [
    "train_sentences.to_hdf(os.path.join(\"preprocessed_data\", \"train_sentences.h5\"), key='s')\n",
    "validation_sentences.to_hdf(os.path.join(\"preprocessed_data\", \"validation_sentences.h5\"), key='s')\n",
    "test_sentences.to_hdf(os.path.join(\"preprocessed_data\", \"test_sentences.h5\"), key='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "interracial-sweden",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexa\\.conda\\envs\\main\\lib\\site-packages\\pandas\\core\\generic.py:2606: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->integer,key->block1_values] [items->Index(['url'], dtype='object')]\n",
      "\n",
      "  pytables.to_hdf(\n"
     ]
    }
   ],
   "source": [
    "train_documents.to_hdf(os.path.join(\"preprocessed_data\", \"train_documents.h5\"), key='s')\n",
    "validation_documents.to_hdf(os.path.join(\"preprocessed_data\", \"validation_documents.h5\"), key='s')\n",
    "test_documents.to_hdf(os.path.join(\"preprocessed_data\", \"test_documents.h5\"), key='s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
