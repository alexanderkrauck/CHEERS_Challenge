{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "technical-syndrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "import os\n",
    "from ast import literal_eval\n",
    "import itertools\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacterial-century",
   "metadata": {},
   "source": [
    "# 1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rough-little",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = \"data_round_1\"\n",
    "\n",
    "l_train_documents = pd.read_csv(os.path.join(data_location,\"documents_en_train.csv\"))\n",
    "l_validation_documents = pd.read_csv(os.path.join(data_location,\"documents_en_val.csv\"))\n",
    "l_test_documents = pd.read_csv(os.path.join(data_location,\"documents_en_test.csv\"))\n",
    "        \n",
    "l_train_sentences = pd.read_csv(os.path.join(data_location,\"sentences_en_train.csv\"), converters={'sector_ids': literal_eval})\n",
    "l_validation_sentences = pd.read_csv(os.path.join(data_location,\"sentences_en_val.csv\"), converters={'sector_ids': literal_eval})\n",
    "l_test_sentences = pd.read_csv(os.path.join(data_location,\"sentences_en_test.csv\"), converters={'sector_ids': literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sophisticated-entrepreneur",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_name</th>\n",
       "      <th>country_code</th>\n",
       "      <th>lang_code</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>doc_text</th>\n",
       "      <th>doc_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMMAP/DFS Syria</td>\n",
       "      <td>SYR</td>\n",
       "      <td>en</td>\n",
       "      <td>48582</td>\n",
       "      <td>This website uses cookies to improve your experience. We'll assume you're ok with this, but you can opt-out if you wish.Accept</td>\n",
       "      <td>https://www.syriahr.com/en/203844/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMMAP/DFS Syria</td>\n",
       "      <td>SYR</td>\n",
       "      <td>en</td>\n",
       "      <td>41032</td>\n",
       "      <td>Please enable Cookies and reload the page.\\n\\nThis process is automatic. Your browser will redirect to your requested content shortly.\\n\\nPlease allow up to 5 seconds…</td>\n",
       "      <td>https://www.syriahr.com/en/187230/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence_text</th>\n",
       "      <th>is_relevant</th>\n",
       "      <th>sector_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51657</td>\n",
       "      <td>0</td>\n",
       "      <td>New Salesian youth center in La Cecilia district serves more than 100 youth (MissionNewswire) Salesian missionaries have opened a youth center in the La Cecilia district of Armenia, Colombia.</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51657</td>\n",
       "      <td>1</td>\n",
       "      <td>Armenia is at the center of the Colombian coffee growing axis.</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(l_train_documents.head(2).to_html()))\n",
    "display(HTML(l_train_sentences.head(2).to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "major-recovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_documents = l_train_documents.copy().set_index(\"doc_id\")\n",
    "validation_documents = l_validation_documents.copy().set_index(\"doc_id\")\n",
    "test_documents = l_test_documents.copy().set_index(\"doc_id\")\n",
    "\n",
    "#Adding one feature here already because its easier on this data-format\n",
    "l_train_sentences[\"sentence_position\"] = l_train_sentences[\"sentence_id\"].apply(lambda x: np.log(x+1))\n",
    "l_validation_sentences[\"sentence_position\"] = l_validation_sentences[\"sentence_id\"].apply(lambda x: np.log(x+1))\n",
    "l_test_sentences[\"sentence_position\"] = l_test_sentences[\"sentence_id\"].apply(lambda x: np.log(x+1))\n",
    "\n",
    "train_sentences = l_train_sentences.copy().set_index([\"doc_id\",\"sentence_id\"])\n",
    "validation_sentences = l_validation_sentences.copy().set_index([\"doc_id\",\"sentence_id\"])\n",
    "test_sentences = l_test_sentences.copy().set_index([\"doc_id\",\"sentence_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-nickname",
   "metadata": {},
   "source": [
    "# 2 Change nominal features to Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "incorporated-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_documents[\"doc_url\"].fillna(\"\",inplace=True)\n",
    "validation_documents[\"doc_url\"].fillna(\"\",inplace=True)\n",
    "test_documents[\"doc_url\"].fillna(\"\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "diagnostic-frank",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name_mapping = dict((o,idx) for idx, o in enumerate(set(train_documents[\"project_name\"])))\n",
    "country_code_mapping = dict((o,idx) for idx, o in enumerate(set(train_documents[\"country_code\"])))\n",
    "url_set = set(train_documents[\"doc_url\"].apply(lambda x: urlparse(x).netloc))\n",
    "document_url_mapping = dict((o,idx) for idx, o in enumerate(url_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "transparent-virginia",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_documents.replace(project_name_mapping, inplace=True)\n",
    "validation_documents.replace(project_name_mapping, inplace=True)\n",
    "test_documents.replace(project_name_mapping, inplace=True)\n",
    "\n",
    "train_documents.replace(country_code_mapping, inplace=True)\n",
    "validation_documents.replace(country_code_mapping, inplace=True)\n",
    "test_documents.replace(country_code_mapping, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "white-antenna",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_documents[\"url\"] = train_documents[\"doc_url\"].apply(lambda x: urlparse(x).netloc).replace(document_url_mapping)\n",
    "validation_documents[\"url\"] = validation_documents[\"doc_url\"].apply(lambda x: urlparse(x).netloc).replace(document_url_mapping)\n",
    "test_documents[\"url\"] = test_documents[\"doc_url\"].apply(lambda x: urlparse(x).netloc).replace(document_url_mapping)\n",
    "#Make unknown (from train set) urls a seperate index\n",
    "for item in validation_documents.iterrows():\n",
    "    if urlparse(item[1][\"doc_url\"]).netloc not in url_set:\n",
    "        validation_documents.loc[item[0], \"url\"] = len(url_set)\n",
    "        \n",
    "for item in test_documents.iterrows():\n",
    "    if urlparse(item[1][\"doc_url\"]).netloc not in url_set:\n",
    "        test_documents.loc[item[0], \"url\"] = len(url_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-maryland",
   "metadata": {},
   "source": [
    "# 3 Extract some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "proud-health",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract document length\n",
    "train_documents[\"text_length\"] = train_documents[\"doc_text\"].apply(len).apply(np.log) #the idea behind log is that the net can use it better (but maybe it is wrong?)\n",
    "validation_documents[\"text_length\"] = validation_documents[\"doc_text\"].apply(len).apply(np.log)\n",
    "test_documents[\"text_length\"] = test_documents[\"doc_text\"].apply(len).apply(np.log)\n",
    "\n",
    "#Extract sentence count in document\n",
    "train_documents[\"sentence_count\"] = train_sentences.groupby(level=\"doc_id\").size().apply(np.log)\n",
    "validation_documents[\"sentence_count\"] = validation_sentences.groupby(level=\"doc_id\").size().apply(np.log)\n",
    "test_documents[\"sentence_count\"] = test_sentences.groupby(level=\"doc_id\").size().apply(np.log)\n",
    "\n",
    "#Extract Sentence Length\n",
    "train_sentences[\"sentence_length\"] = train_sentences[\"sentence_text\"].apply(len).apply(np.log)\n",
    "validation_sentences[\"sentence_length\"] = validation_sentences[\"sentence_text\"].apply(len).apply(np.log)\n",
    "test_sentences[\"sentence_length\"] = test_sentences[\"sentence_text\"].apply(len).apply(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "practical-zoning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_name</th>\n",
       "      <th>country_code</th>\n",
       "      <th>lang_code</th>\n",
       "      <th>doc_text</th>\n",
       "      <th>doc_url</th>\n",
       "      <th>url</th>\n",
       "      <th>text_length</th>\n",
       "      <th>sentence_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40328</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>en</td>\n",
       "      <td>Cox’s Bazar – The International Organization f...</td>\n",
       "      <td>https://reliefweb.int/report/bangladesh/iom-am...</td>\n",
       "      <td>57</td>\n",
       "      <td>7.983099</td>\n",
       "      <td>2.772589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39775</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>en</td>\n",
       "      <td>Introduction The continuation of conflict in N...</td>\n",
       "      <td>https://reliefweb.int/sites/reliefweb.int/file...</td>\n",
       "      <td>57</td>\n",
       "      <td>9.124456</td>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47025</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>Damascus, SANA- Al Mujtahed  Damascus Hospital...</td>\n",
       "      <td>http://sana.sy/en/?p=216501</td>\n",
       "      <td>124</td>\n",
       "      <td>7.271704</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44256</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>Kongoussi, Burkina Faso —Editor's note: In a M...</td>\n",
       "      <td>https://allafrica.com/stories/202010130090.html</td>\n",
       "      <td>7</td>\n",
       "      <td>9.229456</td>\n",
       "      <td>4.110874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35135</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>Pandemic Also Opportunity for Business Elite t...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>8.122074</td>\n",
       "      <td>2.944439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44892</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>CCCM and Shelter/NFI Clusters’ Fire Prevention...</td>\n",
       "      <td>https://reliefweb.int/sites/reliefweb.int/file...</td>\n",
       "      <td>57</td>\n",
       "      <td>9.627009</td>\n",
       "      <td>4.624973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51667</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>en</td>\n",
       "      <td>Bangladesh’s daily infection rate fell slightl...</td>\n",
       "      <td>https://unb.com.bd/category/Bangladesh/covid-1...</td>\n",
       "      <td>96</td>\n",
       "      <td>8.129470</td>\n",
       "      <td>3.367296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40325</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>en</td>\n",
       "      <td>Bangladesh is hosting more than one million Ro...</td>\n",
       "      <td>https://reliefweb.int/report/bangladesh/bangla...</td>\n",
       "      <td>57</td>\n",
       "      <td>7.973500</td>\n",
       "      <td>2.995732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34596</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>July 2020 | Round 2 How COVID-19 compounds alr...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>10.176982</td>\n",
       "      <td>4.934474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51682</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>en</td>\n",
       "      <td>File photo of In a densely populated city like...</td>\n",
       "      <td>https://www.dhakatribune.com/health/coronaviru...</td>\n",
       "      <td>140</td>\n",
       "      <td>7.952615</td>\n",
       "      <td>3.135494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>343 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        project_name  country_code lang_code  \\\n",
       "doc_id                                         \n",
       "40328              2             3        en   \n",
       "39775              3             5        en   \n",
       "47025              0             0        en   \n",
       "44256              1             1        en   \n",
       "35135              0             0        en   \n",
       "...              ...           ...       ...   \n",
       "44892              0             0        en   \n",
       "51667              2             3        en   \n",
       "40325              2             3        en   \n",
       "34596              0             0        en   \n",
       "51682              2             3        en   \n",
       "\n",
       "                                                 doc_text  \\\n",
       "doc_id                                                      \n",
       "40328   Cox’s Bazar – The International Organization f...   \n",
       "39775   Introduction The continuation of conflict in N...   \n",
       "47025   Damascus, SANA- Al Mujtahed  Damascus Hospital...   \n",
       "44256   Kongoussi, Burkina Faso —Editor's note: In a M...   \n",
       "35135   Pandemic Also Opportunity for Business Elite t...   \n",
       "...                                                   ...   \n",
       "44892   CCCM and Shelter/NFI Clusters’ Fire Prevention...   \n",
       "51667   Bangladesh’s daily infection rate fell slightl...   \n",
       "40325   Bangladesh is hosting more than one million Ro...   \n",
       "34596   July 2020 | Round 2 How COVID-19 compounds alr...   \n",
       "51682   File photo of In a densely populated city like...   \n",
       "\n",
       "                                                  doc_url  url  text_length  \\\n",
       "doc_id                                                                        \n",
       "40328   https://reliefweb.int/report/bangladesh/iom-am...   57     7.983099   \n",
       "39775   https://reliefweb.int/sites/reliefweb.int/file...   57     9.124456   \n",
       "47025                         http://sana.sy/en/?p=216501  124     7.271704   \n",
       "44256     https://allafrica.com/stories/202010130090.html    7     9.229456   \n",
       "35135                                                        0     8.122074   \n",
       "...                                                   ...  ...          ...   \n",
       "44892   https://reliefweb.int/sites/reliefweb.int/file...   57     9.627009   \n",
       "51667   https://unb.com.bd/category/Bangladesh/covid-1...   96     8.129470   \n",
       "40325   https://reliefweb.int/report/bangladesh/bangla...   57     7.973500   \n",
       "34596                                                        0    10.176982   \n",
       "51682   https://www.dhakatribune.com/health/coronaviru...  140     7.952615   \n",
       "\n",
       "        sentence_count  \n",
       "doc_id                  \n",
       "40328         2.772589  \n",
       "39775         3.496508  \n",
       "47025         1.609438  \n",
       "44256         4.110874  \n",
       "35135         2.944439  \n",
       "...                ...  \n",
       "44892         4.624973  \n",
       "51667         3.367296  \n",
       "40325         2.995732  \n",
       "34596         4.934474  \n",
       "51682         3.135494  \n",
       "\n",
       "[343 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-investor",
   "metadata": {},
   "source": [
    "- Maybe add target encoding (but I am not sure if it is so powerful since we do not have so many nominal classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-contamination",
   "metadata": {},
   "source": [
    "# 4 Tokenize sentences (first 512 tokens) (lowercase) & remove sentence feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "alien-fellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences[\"tokenized_sentence\"] = train_sentences[\"sentence_text\"].apply(lambda x: tokenizer(x,  max_length=512, truncation=\"longest_first\")[\"input_ids\"])\n",
    "validation_sentences[\"tokenized_sentence\"] = validation_sentences[\"sentence_text\"].apply(lambda x: tokenizer(x, max_length=512, truncation=\"longest_first\")[\"input_ids\"])\n",
    "test_sentences[\"tokenized_sentence\"] = test_sentences[\"sentence_text\"].apply(lambda x: tokenizer(x, max_length=512, truncation=\"longest_first\")[\"input_ids\"])\n",
    "\n",
    "train_sentences.drop(\"sentence_text\", axis=\"columns\", inplace= True)\n",
    "validation_sentences.drop(\"sentence_text\", axis=\"columns\", inplace= True)\n",
    "test_sentences.drop(\"sentence_text\", axis=\"columns\", inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-frost",
   "metadata": {},
   "source": [
    "# 5 Remove unnecessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "suffering-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_documents.drop(\"lang_code\",axis=\"columns\", inplace = True)\n",
    "validation_documents.drop(\"lang_code\",axis=\"columns\", inplace = True)\n",
    "test_documents.drop(\"lang_code\",axis=\"columns\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "polish-dimension",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_documents.drop(\"doc_text\",axis=\"columns\", inplace = True)\n",
    "validation_documents.drop(\"doc_text\",axis=\"columns\", inplace = True)\n",
    "test_documents.drop(\"doc_text\",axis=\"columns\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "framed-zealand",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_documents.drop(\"doc_url\",axis=\"columns\", inplace = True)\n",
    "validation_documents.drop(\"doc_url\",axis=\"columns\", inplace = True)\n",
    "test_documents.drop(\"doc_url\",axis=\"columns\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "referenced-congress",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_name</th>\n",
       "      <th>country_code</th>\n",
       "      <th>url</th>\n",
       "      <th>text_length</th>\n",
       "      <th>sentence_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48582</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>4.836282</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41032</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>5.093750</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>is_relevant</th>\n",
       "      <th>sector_ids</th>\n",
       "      <th>sentence_position</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>tokenized_sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">51657</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.252273</td>\n",
       "      <td>[101, 2047, 4341, 2937, 3360, 2415, 1999, 2474, 18459, 2212, 4240, 2062, 2084, 2531, 3360, 1006, 3260, 2638, 9333, 20357, 1007, 4341, 2937, 11743, 2031, 2441, 1037, 3360, 2415, 1999, 1996, 2474, 18459, 2212, 1997, 10110, 1010, 7379, 1012, 102]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>4.127134</td>\n",
       "      <td>[101, 10110, 2003, 2012, 1996, 2415, 1997, 1996, 13598, 4157, 3652, 8123, 1012, 102]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(train_documents.head(2).to_html()))\n",
    "display(HTML(train_sentences.head(2).to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-measure",
   "metadata": {},
   "source": [
    "# 6 Normalize (Numerical) Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "violent-crazy",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_document_text_length_mean = train_documents[\"text_length\"].mean()\n",
    "train_document_sentence_count_mean = train_documents[\"sentence_count\"].mean()\n",
    "train_sentence_position_mean = train_sentences[\"sentence_position\"].mean()\n",
    "train_sentence_length_mean = train_sentences[\"sentence_length\"].mean()\n",
    "\n",
    "train_document_text_length_std = train_documents[\"text_length\"].std()\n",
    "train_document_sentence_count_std = train_documents[\"sentence_count\"].std()\n",
    "train_sentence_position_std = train_sentences[\"sentence_position\"].std()\n",
    "train_sentence_length_std = train_sentences[\"sentence_length\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "faced-stocks",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_documents[\"text_length\"] = (train_documents[\"text_length\"] - train_document_text_length_mean) / train_document_text_length_std\n",
    "validation_documents[\"text_length\"] = (validation_documents[\"text_length\"] - train_document_text_length_mean) / train_document_text_length_std\n",
    "test_documents[\"text_length\"] = (test_documents[\"text_length\"] - train_document_text_length_mean) / train_document_text_length_std\n",
    "\n",
    "train_documents[\"sentence_count\"] = (train_documents[\"sentence_count\"] - train_document_sentence_count_mean) / train_document_sentence_count_std\n",
    "validation_documents[\"sentence_count\"] = (validation_documents[\"sentence_count\"] - train_document_sentence_count_mean) / train_document_sentence_count_std\n",
    "test_documents[\"sentence_count\"] = (test_documents[\"sentence_count\"] - train_document_sentence_count_mean) / train_document_sentence_count_std\n",
    "\n",
    "train_sentences[\"sentence_position\"] = (train_sentences[\"sentence_position\"] - train_sentence_position_mean) / train_sentence_position_std\n",
    "validation_sentences[\"sentence_position\"] = (validation_sentences[\"sentence_position\"] - train_sentence_position_mean) / train_sentence_position_std\n",
    "test_sentences[\"sentence_position\"] = (test_sentences[\"sentence_position\"] - train_sentence_position_mean) / train_sentence_position_std\n",
    "\n",
    "train_sentences[\"sentence_length\"] = (train_sentences[\"sentence_length\"] - train_sentence_length_mean) / train_sentence_length_std\n",
    "validation_sentences[\"sentence_length\"] = (validation_sentences[\"sentence_length\"] - train_sentence_length_mean) / train_sentence_length_std\n",
    "test_sentences[\"sentence_length\"] = (test_sentences[\"sentence_length\"] - train_sentence_length_mean) / train_sentence_length_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-jersey",
   "metadata": {},
   "source": [
    "# 7 Join together and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "falling-facial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>is_relevant</th>\n",
       "      <th>sector_ids</th>\n",
       "      <th>sentence_position</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>tokenized_sentence</th>\n",
       "      <th>project_name</th>\n",
       "      <th>country_code</th>\n",
       "      <th>url</th>\n",
       "      <th>text_length</th>\n",
       "      <th>sentence_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">51657</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>-2.396411</td>\n",
       "      <td>0.569648</td>\n",
       "      <td>[101, 2047, 4341, 2937, 3360, 2415, 1999, 2474...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>119</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>-0.295492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>-2.077704</td>\n",
       "      <td>-0.124752</td>\n",
       "      <td>[101, 10110, 2003, 2012, 1996, 2415, 1997, 199...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>119</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>-0.295492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>-1.891273</td>\n",
       "      <td>0.217774</td>\n",
       "      <td>[101, 1996, 2047, 3360, 2415, 2038, 2366, 2062...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>119</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>-0.295492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>-1.758998</td>\n",
       "      <td>0.336929</td>\n",
       "      <td>[101, 1996, 4341, 2937, 3360, 2415, 2001, 2764...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>119</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>-0.295492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>-1.656397</td>\n",
       "      <td>-0.076886</td>\n",
       "      <td>[101, 2116, 1997, 2122, 3360, 2272, 2013, 3532...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>119</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>-0.295492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">34512</th>\n",
       "      <th>121</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>-0.187538</td>\n",
       "      <td>-0.058732</td>\n",
       "      <td>[101, 2174, 1010, 11470, 19621, 2015, 2024, 20...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.055759</td>\n",
       "      <td>1.123685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>-0.183785</td>\n",
       "      <td>0.424618</td>\n",
       "      <td>[101, 1999, 5712, 1010, 2045, 2024, 4311, 1997...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.055759</td>\n",
       "      <td>1.123685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>-0.180062</td>\n",
       "      <td>-0.058732</td>\n",
       "      <td>[101, 1996, 9353, 9331, 2015, 2136, 2097, 2562...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.055759</td>\n",
       "      <td>1.123685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>-0.176368</td>\n",
       "      <td>-0.095589</td>\n",
       "      <td>[101, 2017, 2064, 2424, 2019, 19184, 1997, 203...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.055759</td>\n",
       "      <td>1.123685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>-0.172705</td>\n",
       "      <td>0.673494</td>\n",
       "      <td>[101, 2340, 9353, 9331, 2015, 11470, 3229, 191...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.055759</td>\n",
       "      <td>1.123685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261981 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    is_relevant sector_ids  sentence_position  \\\n",
       "doc_id sentence_id                                              \n",
       "51657  0                      0         []          -2.396411   \n",
       "       1                      0         []          -2.077704   \n",
       "       2                      0         []          -1.891273   \n",
       "       3                      0         []          -1.758998   \n",
       "       4                      0         []          -1.656397   \n",
       "...                         ...        ...                ...   \n",
       "34512  121                    0         []          -0.187538   \n",
       "       122                    0         []          -0.183785   \n",
       "       123                    0         []          -0.180062   \n",
       "       124                    0         []          -0.176368   \n",
       "       125                    0         []          -0.172705   \n",
       "\n",
       "                    sentence_length  \\\n",
       "doc_id sentence_id                    \n",
       "51657  0                   0.569648   \n",
       "       1                  -0.124752   \n",
       "       2                   0.217774   \n",
       "       3                   0.336929   \n",
       "       4                  -0.076886   \n",
       "...                             ...   \n",
       "34512  121                -0.058732   \n",
       "       122                 0.424618   \n",
       "       123                -0.058732   \n",
       "       124                -0.095589   \n",
       "       125                 0.673494   \n",
       "\n",
       "                                                   tokenized_sentence  \\\n",
       "doc_id sentence_id                                                      \n",
       "51657  0            [101, 2047, 4341, 2937, 3360, 2415, 1999, 2474...   \n",
       "       1            [101, 10110, 2003, 2012, 1996, 2415, 1997, 199...   \n",
       "       2            [101, 1996, 2047, 3360, 2415, 2038, 2366, 2062...   \n",
       "       3            [101, 1996, 4341, 2937, 3360, 2415, 2001, 2764...   \n",
       "       4            [101, 2116, 1997, 2122, 3360, 2272, 2013, 3532...   \n",
       "...                                                               ...   \n",
       "34512  121          [101, 2174, 1010, 11470, 19621, 2015, 2024, 20...   \n",
       "       122          [101, 1999, 5712, 1010, 2045, 2024, 4311, 1997...   \n",
       "       123          [101, 1996, 9353, 9331, 2015, 2136, 2097, 2562...   \n",
       "       124          [101, 2017, 2064, 2424, 2019, 19184, 1997, 203...   \n",
       "       125          [101, 2340, 9353, 9331, 2015, 11470, 3229, 191...   \n",
       "\n",
       "                    project_name  country_code  url  text_length  \\\n",
       "doc_id sentence_id                                                 \n",
       "51657  0                       5             4  119    -0.605825   \n",
       "       1                       5             4  119    -0.605825   \n",
       "       2                       5             4  119    -0.605825   \n",
       "       3                       5             4  119    -0.605825   \n",
       "       4                       5             4  119    -0.605825   \n",
       "...                          ...           ...  ...          ...   \n",
       "34512  121                     0             0    0     1.055759   \n",
       "       122                     0             0    0     1.055759   \n",
       "       123                     0             0    0     1.055759   \n",
       "       124                     0             0    0     1.055759   \n",
       "       125                     0             0    0     1.055759   \n",
       "\n",
       "                    sentence_count  \n",
       "doc_id sentence_id                  \n",
       "51657  0                 -0.295492  \n",
       "       1                 -0.295492  \n",
       "       2                 -0.295492  \n",
       "       3                 -0.295492  \n",
       "       4                 -0.295492  \n",
       "...                            ...  \n",
       "34512  121                1.123685  \n",
       "       122                1.123685  \n",
       "       123                1.123685  \n",
       "       124                1.123685  \n",
       "       125                1.123685  \n",
       "\n",
       "[261981 rows x 10 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_joint = train_sentences.join(train_documents, on=\"doc_id\")\n",
    "validation_joint = validation_sentences.join(validation_documents, on=\"doc_id\")\n",
    "test_joint = test_sentences.join(test_documents, on=\"doc_id\")\n",
    "train_joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "weighted-brick",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexa\\.conda\\envs\\main\\lib\\site-packages\\pandas\\core\\generic.py:2606: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['sector_ids', 'tokenized_sentence'], dtype='object')]\n",
      "\n",
      "  pytables.to_hdf(\n",
      "C:\\Users\\alexa\\.conda\\envs\\main\\lib\\site-packages\\pandas\\core\\generic.py:2606: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed-integer,key->block2_values] [items->Index(['sector_ids', 'tokenized_sentence', 'url'], dtype='object')]\n",
      "\n",
      "  pytables.to_hdf(\n",
      "C:\\Users\\alexa\\.conda\\envs\\main\\lib\\site-packages\\pandas\\core\\generic.py:2606: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed-integer,key->block2_values] [items->Index(['tokenized_sentence', 'url'], dtype='object')]\n",
      "\n",
      "  pytables.to_hdf(\n"
     ]
    }
   ],
   "source": [
    "train_joint.to_hdf(os.path.join(\"preprocessed_data\", \"train_joint.h5\"), key='s')\n",
    "validation_joint.to_hdf(os.path.join(\"preprocessed_data\", \"validation_joint.h5\"), key='s')\n",
    "test_joint.to_hdf(os.path.join(\"preprocessed_data\", \"test_joint.h5\"), key='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "sound-primary",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexa\\.conda\\envs\\main\\lib\\site-packages\\pandas\\core\\generic.py:2606: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->Index(['sector_ids', 'tokenized_sentence'], dtype='object')]\n",
      "\n",
      "  pytables.to_hdf(\n",
      "C:\\Users\\alexa\\.conda\\envs\\main\\lib\\site-packages\\pandas\\core\\generic.py:2606: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->Index(['tokenized_sentence'], dtype='object')]\n",
      "\n",
      "  pytables.to_hdf(\n"
     ]
    }
   ],
   "source": [
    "train_sentences.to_hdf(os.path.join(\"preprocessed_data\", \"train_sentences.h5\"), key='s')\n",
    "validation_sentences.to_hdf(os.path.join(\"preprocessed_data\", \"validation_sentences.h5\"), key='s')\n",
    "test_sentences.to_hdf(os.path.join(\"preprocessed_data\", \"test_sentences.h5\"), key='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "convertible-inspector",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexa\\.conda\\envs\\main\\lib\\site-packages\\pandas\\core\\generic.py:2606: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->integer,key->block1_values] [items->Index(['url'], dtype='object')]\n",
      "\n",
      "  pytables.to_hdf(\n"
     ]
    }
   ],
   "source": [
    "train_documents.to_hdf(os.path.join(\"preprocessed_data\", \"train_documents.h5\"), key='s')\n",
    "validation_documents.to_hdf(os.path.join(\"preprocessed_data\", \"validation_documents.h5\"), key='s')\n",
    "test_documents.to_hdf(os.path.join(\"preprocessed_data\", \"test_documents.h5\"), key='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-tactics",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
