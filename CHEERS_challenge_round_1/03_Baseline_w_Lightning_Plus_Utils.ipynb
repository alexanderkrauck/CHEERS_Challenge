{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from utils.data import IsRelevantDataset\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    \n",
    "from transformers import BertModel\n",
    "bert_id = \"google/bert_uncased_L-2_H-128_A-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelevantModule(pl.LightningModule):\n",
    "    def __init__(self, bert: BertModel, input_size: int, output_size: int, start_lr=1e-4):\n",
    "        super().__init__()        \n",
    "        self.bert = bert\n",
    "        self.linear_after_bert = nn.Linear(bert.config.hidden_size, 256)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            #nn.BatchNorm1d(bert.config.hidden_size + input_size),#just a feeling this might be nice\n",
    "            nn.Linear(256 + input_size, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(64, output_size)\n",
    "        )\n",
    "        \n",
    "        for \n",
    "        \n",
    "        self.start_lr = start_lr\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_bert = x[0]\n",
    "        x_other = x[1]\n",
    "        y_bert = self.bert(x[0])[\"last_hidden_state\"][:,0] #all batches but only clf output\n",
    "        y_bert = self.linear_after_bert(y_bert)\n",
    "        x = torch.cat((y_bert, x_other), dim=1)#dim=1 is feature dimensions (0 is batch dim)\n",
    "        \n",
    "        return self.feed_forward(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.start_lr)\n",
    "        #return optimizer\n",
    "        return {\n",
    "           'optimizer': optimizer,\n",
    "           'lr_scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True, factor =.2, patience =1, cooldown =2, min_lr =1e-6),\n",
    "           'monitor': 'val_loss'\n",
    "       }\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "\n",
    "        y_hat = self.forward(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        acc = torch.sum(torch.argmax(y_hat, dim=-1) == y) / len(y)\n",
    "\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"val_acc\", acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_joint = pd.read_hdf(join(\"preprocessed_data\",\"train_joint.h5\"), key=\"s\")\n",
    "validation_join = pd.read_hdf(join(\"preprocessed_data\",\"validation_joint.h5\"), key=\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = IsRelevantDataset(train_joint, device = device)\n",
    "validation_ds = IsRelevantDataset(validation_join, device = device, dimensions = train_ds.dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "batch_size=16\n",
    "epochs = 10\n",
    "bert_hidden = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds,batch_size  = batch_size, shuffle=True)\n",
    "validation_dl = DataLoader(train_ds, batch_size  = 64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "Using native 16bit precision.\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "model = RelevantModule(BertModel.from_pretrained(bert_id).to(device), sum(train_ds.dimensions[0][1]), train_ds.dimensions[1])\n",
    "#logging\n",
    "tb_logger = pl_loggers.TensorBoardLogger('logs', name=\"No_Normalization\")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='checkpoints/',\n",
    "    filename='-{epoch:02d}-{val_loss:.2f}'\n",
    ")\n",
    "# training\n",
    "trainer = Trainer(gpus=1, precision=16, logger=tb_logger, callbacks=[checkpoint_callback], num_sanity_val_steps = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type       | Params\n",
      "-------------------------------------------------\n",
      "0 | bert              | BertModel  | 4.4 M \n",
      "1 | linear_after_bert | Linear     | 33.0 K\n",
      "2 | feed_forward      | Sequential | 713 K \n",
      "-------------------------------------------------\n",
      "5.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.1 M     Total params\n",
      "20.528    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5960a15768d8432ea4e79e4596193982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "592146664bdc41c4b73974d3ef216398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model, train_dl, validation_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
